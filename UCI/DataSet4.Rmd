---
title: "DataSet4 - Ionosphere"
author: "Sungcheol Kim"
date: "12/19/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(mlbench)
library(pander)
source('rprob-new.R')
```

## Prepare Data

```{r Ionosphere, cache=TRUE}
data(Ionosphere)

dataset <- Ionosphere
dataset <- dataset[,-2]
dataset$V1 <- as.numeric(as.character(dataset$V1))
head(dataset)
```

```{r initial analysis, cache=TRUE}
set.seed(1)
seeds <- vector(mode = "list", length = 51)
for(i in 1:50) seeds[[i]] <- sample.int(1000, 22)

## For the last model:
seeds[[51]] <- sample.int(1000, 1)

fitControl1 <- trainControl(method = "adaptive_cv",
                           repeats = 5,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary, 
                           search = "random", 
                           seeds = seeds)

fitControl2 <- trainControl(method = "repeatedcv",
                           repeats = 5,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary, 
                           search = "random", 
                           seeds = seeds)

#gbmGrid <-  expand.grid(interaction.depth = c(3,5,7), 
#                        n.trees = (2:7)*50, 
#                        shrinkage = 0.1,
#                        n.minobsinnode = 20)

#set.seed(200)
inTraining0 <- createDataPartition(dataset$Class, p = .75, list = FALSE)
training <- dataset[ inTraining0,]
testing  <- dataset[-inTraining0,]
testingY <- dataset[-inTraining0, ncol(dataset)]
rho <- findrho(testingY, 'good')

print(rho)
```

## Train with algorithms

```{r ababoost algorithm}
adbFit <- multicore_train("adb", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
adbFit
```


```{r Model Averaged Neural Network algorithm}
avNFit <- multicore_train("avN", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
avNFit
```

```{r Bayesian Generalized Linear Model algorithm}
bglmFit <- multicore_train("bglm", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
bglmFit
```
```{r Multivariate Adaptive Regression Spline algorithm}
earthFit <- multicore_train("earth", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
earthFit
```

```{r Lasso and Elastic-Net Regularized Generalized Linear Models algorithm}
glmnetFit <- multicore_train("glmnet", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
glmnetFit
```

```{r Decision Trees and Rule-Based Models algorithm}
C50Fit <- multicore_train("C50", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
C50Fit
```

```{r k-Nearest Neighbors algorithm}
knnFit <- multicore_train("knn", Class ~ ., training, fitControl2, 5, dataName = "Ionosphere")
knnFit
```

```{r Multi-layer Perceptron algorithm}
mlpFit <- multicore_train("mlp", Class ~ ., training, fitControl2, 5, dataName = "Ionosphere")
mlpFit
```

```{r Naive Bayes algorithm}
nbFit <- multicore_train("nb", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
nbFit
```

```{r Neural Network algorithm}
nnetFit <- multicore_train("nnet", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
nnetFit
```

```{r Recursive Partitioning and Regression Trees algorithm}
rpartFit <- multicore_train("rpart", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
rpartFit
```

```{r Conditional Inferernce Tree algorithm}
ctreeFit <- multicore_train("ctree", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
ctreeFit
```

```{r eXtreme Gradient Boosting algorithm}
xgbFit <- multicore_train("xgbTree", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
xgbFit
```

```{r Stochastic Gradient Boosting algorithm}
gbmFit <- multicore_train("gbm", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere")
gbmFit
```

```{r Support Vector Machine with Radial Kernel algorithm}
svmFit <- multicore_train("svm", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere", save=F)
svmFit
```

```{r Regularized Discriminant Analysis algorithm}
rdaFit <- multicore_train("rda", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere", save=F)
rdaFit
```

```{r Partial Least Squares algorithm}
plsFit <- multicore_train("pls", Class ~ ., training, fitControl2, 6, dataName = "Ionosphere", save=F)
plsFit
```

```{r Boosted Logistic Regression algorithm}
lgbFit <- multicore_train("lgb", Class ~ ., training, fitControl2, 6, dataName = "Ionosphere", save=F)
lgbFit
```

```{r Parallel Random Forest algorithm}
pRFFit <- multicore_train("pRF", Class ~ ., training, fitControl2, 4, dataName = "Ionosphere", save=F)
pRFFit
```

## Hyperparameter Fittings

```{r hyper-parameters fitting }
modellist.all <- list(adbFit, avNFit, C50Fit, ctreeFit, earthFit, gbmFit, glmnetFit, knnFit, lgbFit, mlpFit, nbFit, nnetFit, plsFit, pRFFit, rdaFit, rpartFit, svmFit, xgbFit)
modelnamelist.all <- character(0)

for (m in modellist.all) {
  mname <- m$method
  modelnamelist.all <- c(modelnamelist.all, mname)
  fname <- paste0('Dataset4_hpfit_', mname, '.pdf')
  cat(fname, '\n')
  pdf(file = fname, width = 8, height = 6)
  p <- plot(m)
  print(p)
  dev.off()
}

modelnamelist.all
```

```{r}
names(modellist.all) <- modelnamelist.all
combined_result <- resamples(modellist.all)
```

```{r}
dotplot(combined_result)
```

```{r}
# correlation between results
res <- modelCor(combined_result)
pander(res)
splom(combined_result)
```

## Prepare SUMMA+

```{r}
#lambda.gbm <- findlambda(gbmFit, newdata = testing, Y = testingY, rho = rho, save.pdf = T)
```

```{r}
summaFit <- summaplus_train(modellist.all, dataName = 'Ionosphere')
lambda.summa <- findlambda(summaFit, newdata = testing, Y = testingY, rho = rho, save.pdf = T)
```

```{r}
roc.gbm <- modelplot.roc(rdaFit, testing, testingY, rho, save.pdf=T)
```

```{r}
rankplot.gbm <- modelplot.rank(list(rdaFit, svmFit, adbFit, pRFFit, gbmFit), testing, rho)
rankplot.gbm
```

```{r}
findlambda(rdaFit, newdata = testing, Y = testingY, rho = rho)
```

