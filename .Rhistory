testingY <- as_label(Sonar[-inTraining0, ncol(Sonar)])
fde1 <- fde(p, testingY)
plot_cor(fde1)
?createResample
devtools::load_all(".")
library(mlbench)
library(FDclassifieR)
#set.seed(1024)
data(Sonar)
inTraining0 <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
#set.seed(1024)
data(Sonar)
inTraining0 <- caret::createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining0,]
testing  <- Sonar[-inTraining0,]
testingY <- as_label(Sonar[-inTraining0, ncol(Sonar)])
devtools::load_all(".")
library(mlbench)
library(FDclassifieR)
#set.seed(1024)
data(Sonar)
inTraining0 <- caret::createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining0,]
testing  <- Sonar[-inTraining0,]
testingY <- as_label(Sonar[-inTraining0, ncol(Sonar)])
#set.seed(1024)
data(Sonar)
inTraining0 <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining0,]
testing  <- Sonar[-inTraining0,]
testingY <- as_label(Sonar[-inTraining0, ncol(Sonar)])
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
t1 <- t1 %>%
addmodel.mtrainer(c('svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet')) %>%
train(Class~., training, update=F)
plot(t1)
t1 <- predict(t1, newdata=testing)
auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions)
fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_cor(fde1, legend_flag = T)
fde1 <- fde(t1$predictions, testingY)
store.mtrainer(t1)
store.mtrainer(t1, 'sonar_m8.RData')
t1$predictions
store.mtrainer(t1, 'sonar_m8_pre.RData')
saveRDS(testingY, 'sonar_m8_y.RData')
plot_single(fde1, 'score')
plot_single(fde1, 'score', 2)
knitr::opts_chunk$set(echo = TRUE)
library(FDclassifieR)
prepareData <- function(fname) {
temp <- read.csv(fname, sep = ';')
#dummies <- dummyVars(y ~ ., data = df)
#ndf <- predict(dummies, newdata = df)
return(temp)
}
df <- prepareData('bank.csv')
prepareData <- function(fname) {
temp <- read.csv(fname, sep = ';')
#dummies <- dummyVars(y ~ ., data = df)
#ndf <- predict(dummies, newdata = df)
return(temp)
}
df <- prepareData('bank.csv')
table(df$y)
rho = 521/(4000 + 521)
rho
Bank <- read.csv('bank.csv', sep=';')
inTraining0 <- createDataPartition(Bank$y, p = .75, list = FALSE)
training <- Bank[ inTraining0,]
testing  <- Bank[-inTraining0,]
testingY <- as_label(Bank[-inTraining0, ncol(Sonar)])
Bank <- read.csv('bank.csv', sep=';')
inTraining0 <- createDataPartition(Bank$y, p = .75, list = FALSE)
training <- Bank[ inTraining0,]
testing  <- Bank[-inTraining0,]
testingY <- as_label(Bank[-inTraining0, ncol(Bank)])
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(y~., training, update=F) %>%
predict(newdata=testing)
plot(t1)
t1 <- predict(t1, newdata=testing)
auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions)
fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_cor(fde1, legend_flag = T)
fde1 <- fde(t1$predictions, testingY)
plot_single(fde1, 'score')
store.mtrainer(t1, 'bank_m8_pre.RData')
saveRDS(testingY, 'bank_m8_y.RData')
t1 <- t1 %>%
addmodel.mtrainer(c('ctree', 'C5.0', 'gbm')) %>%
train(Class~., training, update=F)
t1 <- t1 %>%
addmodel.mtrainer(c('ctree', 'C5.0', 'gbm')) %>%
train(y~., training, update=F)
plot(t1)
t1 <- predict(t1, newdata=testing)
auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions)
fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_cor(fde1, legend_flag = T)
fde1 <- fde(t1$predictions, testingY)
plot_single(fde1, 'score')
store.mtrainer(t1, 'bank_m8_pre.RData')
saveRDS(testingY, 'bank_m8_y.RData')
table(Bank[ inTraining0, ncol(Bank)])
t1 <- t1 %>%
addmodel.mtrainer(c('svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet')) %>%
train(y~., training, update=F) %>%
predict(newdata=testingY)
t1 <- t1 %>%
addmodel.mtrainer(c('svmLinear', 'svmRadial', 'pls', 'earth', 'avNNet')) %>%
train(y~., training, update=F) %>%
predict(newdata=testingY)
t1 <- predict(t1, newdata=testing)
auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions)
fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
devtools::load_all(".")
plot(t1)
knitr::opts_chunk$set(echo = TRUE)
library(mlbench)
library(FDclassifieR)
knitr::opts_chunk$set(echo = TRUE)
library(mlbench)
library(FDclassifieR)
data(Ionosphere)
df <- Ionosphere
df <- df[,-2]
df$V1 <- as.numeric(as.character(df$V1))
str(df)
data(Ionosphere)
Iono <- Ionosphere
Iono <- Iono[,-2]
Iono$V1 <- as.numeric(as.character(Iono$V1))
inTraining0 <- createDataPartition(Iono$Class, p = .75, list = FALSE)
devtools::load_all(".")
knitr::opts_chunk$set(echo = TRUE)
library(mlbench)
library(FDclassifieR)
data(Ionosphere)
Iono <- Ionosphere
Iono <- Iono[,-2]
Iono$V1 <- as.numeric(as.character(Iono$V1))
inTraining0 <- createDataPartition(Iono$Class, p = .75, list = FALSE)
training <- Iono[ inTraining0,]
testing  <- Iono[-inTraining0,]
testingY <- as_label(Iono[-inTraining0, ncol(Iono)])
table(Iono[ inTraining0, ncol(Iono)])
}
table(Iono[ inTraining0, ncol(Iono)])
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
plot(t1)
t1 <- t1 %>%
addmodel.mtrainer(c('ctree', 'C5.0', 'gbm')) %>%
train(y~., training) %>%
predict(newdata=testing)
t1 <- t1 %>%
addmodel(c('ctree', 'C5.0', 'gbm')) %>%
train(Class~., training) %>%
predict(newdata=testing)
t1 <- t1 %>%
addmodel.mtrainer(c('ctree', 'C5.0', 'gbm')) %>%
train(Class~., training) %>%
predict(newdata=testing)
#t1 <- predict(t1, newdata=testing)
auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions)
fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_cor(fde1, legend_flag = T)
fde1 <- fde(t1$predictions, testingY)
plot_cor(fde1, legend_flag = T)
plot_single(fde1, 'score')
store.mtrainer(t1, 'iono_m8_pre.RData')
saveRDS(testingY, 'iono_m8_y.RData')
saveRDS(t1, 'iono_all.RData')
devtools::load_all(".")
knitr::opts_chunk$set(echo = TRUE)
library(FDclassifieR)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
yeast <- read.table('yeast.data')
names(yeast)<- c("SequenceName", "mcg", "gvh", "alm", "mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#yeast$LocalizationSite <- as.factor(yeast$LocalizationSite)
#head(yeast)
#table(yeast$LocalizationSite)
df <- yeast[yeast$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(df)[ncol(df)] <- 'Class'
df$Class <- factor(df$Class, c('CYT', 'NUC'))
#head(df)
table(df$Class)
table(Yeast[ inTraining0, ncol(Yeast)])
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('yeast.data')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Class, c('CYT', 'NUC'))
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('yeast.data')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Class, p = .75, list = FALSE)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('yeast.data')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
table(Yeast[ inTraining0, ncol(Yeast)])
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('yeast.data')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
table(tmp$LocalizationSite)
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Site~., training, update=F) %>%
predict(newdata=testing)
plot(t1)
summary(s1)
t1 <- t1 %>%
addmodel.mtrainer(c('ctree', 'C5.0', 'gbm')) %>%
train(Class~., training) %>%
predict(newdata=testing)
t1 <- t1 %>%
addmodel.mtrainer(c('ctree', 'C5.0', 'gbm')) %>%
train(Site~., training) %>%
predict(newdata=testing)
#t1 <- predict(t1, newdata=testing)
auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions)
fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_cor(fde1, legend_flag = T)
fde1 <- fde(t1$predictions, testingY)
plot_single(fde1, 'score')
store.mtrainer(t1, 'yeast_m8_pre.RData')
saveRDS(testingY, 'yeast_m8_y.RData')
saveRDS(t1, 'yeast_all.RData')
knitr::opts_chunk$set(echo = TRUE)
library(caret)
tag <- read.csv("tag_data.csv", row.names = 1)
library(caret)
tag <- read.csv("tag_data.csv", row.names = 1)
tag <- as.matrix(tag)
## Select only models for regression
regModels <- tag[tag[,"Classification"] == 1,]
all <- 1:nrow(regModels)
## Seed the analysis with the SVM model
start <- grep("(gbm)", rownames(regModels), fixed = TRUE)
pool <- all[all != start]
## Select 4 model models by maximizing the Jaccard
## dissimilarity between sets of models
nextMods <- maxDissim(regModels[start,,drop = FALSE],
regModels[pool, ],
method = "Jaccard",
n = 4)
rownames(regModels)[c(start, nextMods)]
library(caret)
tag <- read.csv("tag_data.csv", row.names = 1)
tag <- as.matrix(tag)
## Select only models for regression
regModels <- tag[tag[,"Classification"] == 1,]
all <- 1:nrow(regModels)
## Seed the analysis with the SVM model
start <- grep("(gbm)", rownames(regModels), fixed = TRUE)
pool <- all[all != start]
## Select 4 model models by maximizing the Jaccard
## dissimilarity between sets of models
nextMods <- maxDissim(regModels[start,,drop = FALSE],
regModels[pool, ],
method = "Jaccard",
n = 10)
rownames(regModels)[c(start, nextMods)]
library(caret)
tag <- read.csv("tag_data.csv", row.names = 1)
tag <- as.matrix(tag)
## Select only models for regression
regModels <- tag[tag[,"Classification"] == 1,]
all <- 1:nrow(regModels)
## Seed the analysis with the SVM model
start <- grep("(svm)", rownames(regModels), fixed = TRUE)
pool <- all[all != start]
## Select 4 model models by maximizing the Jaccard
## dissimilarity between sets of models
nextMods <- maxDissim(regModels[start,,drop = FALSE],
regModels[pool, ],
method = "Jaccard",
n = 10)
library(caret)
tag <- read.csv("tag_data.csv", row.names = 1)
tag <- as.matrix(tag)
## Select only models for regression
regModels <- tag[tag[,"Classification"] == 1,]
all <- 1:nrow(regModels)
## Seed the analysis with the SVM model
start <- grep("(SVM)", rownames(regModels), fixed = TRUE)
pool <- all[all != start]
## Select 4 model models by maximizing the Jaccard
## dissimilarity between sets of models
nextMods <- maxDissim(regModels[start,,drop = FALSE],
regModels[pool, ],
method = "Jaccard",
n = 10)
library(caret)
tag <- read.csv("tag_data.csv", row.names = 1)
tag <- as.matrix(tag)
## Select only models for regression
regModels <- tag[tag[,"Classification"] == 1,]
all <- 1:nrow(regModels)
## Seed the analysis with the SVM model
start <- grep("(gbm)", rownames(regModels), fixed = TRUE)
pool <- all[all != start]
## Select 4 model models by maximizing the Jaccard
## dissimilarity between sets of models
nextMods <- maxDissim(regModels[start,,drop = FALSE],
regModels[pool, ],
method = "Jaccard",
n = 10)
rownames(regModels)[c(start, nextMods)]
pca <- princomp(tmp[, 2:9], cor=T) # principal components analysis using correlation matrix
pc.comp <- pca$scores
PrincipalComponent1 <- -1*pc.comp[,1] # principal component 1 scores (negated for convenience)
PrincipalComponent2 <- -1*pc.comp[,2] # principal component 2 scores (negated for convenience)
clustering.data <- cbind(PrincipalComponent1, PrincipalComponent2)
set.seed(100)
km <- kmeans(clustering.data, 8, iter.max = 30, nstart=30)
km
km$cluster
plot(PrincipalComponent1, PrincipalComponent2, col=km$cluster)
points(km$centers, pch=16)
aggregate(yeast[, 2:9],by=list(km$cluster),mean)
set.seed(100)
km <- kmeans(clustering.data, 8, iter.max = 30, nstart=30)
km
km$cluster
plot(PrincipalComponent1, PrincipalComponent2, col=km$cluster)
points(km$centers, pch=16)
aggregate(tmp[, 2:9],by=list(km$cluster),mean)
table(km$cluster, tmp$LocalizationSite)
library(kknn)
cl   <- specClust(clustering.data, centers=8, nn=50, iter.max=100)
cl
plot(PrincipalComponent1, PrincipalComponent2, col=cl$cluster)
table(cl$cluster, yeast$LocalizationSite)
library(kknn)
cl   <- specClust(clustering.data, centers=8, nn=50, iter.max=100)
cl
plot(PrincipalComponent1, PrincipalComponent2, col=cl$cluster)
table(cl$cluster, tmp$LocalizationSite)
aggregate(tmp[, 2:9],by=list(cl$cluster),mean)
d_yeast<- dist(clustering.data)
hclusters <- hclust(d_yeast, method = "average")
clusterCut <- cutree(hclusters, 8)
clusterCut
table(clusterCut, yeast$LocalizationSite)
d_yeast<- dist(clustering.data)
hclusters <- hclust(d_yeast, method = "average")
clusterCut <- cutree(hclusters, 8)
clusterCut
table(clusterCut, tmp$LocalizationSite)
aggregate(tmp[, 2:9],by=list(clusterCut),mean)
plot(PrincipalComponent1, PrincipalComponent2, col=clusterCut)
d_yeast<- dist(clustering.data)
hclusters <- hclust(d_yeast, method = "average")
clusterCut <- cutree(hclusters, 8)
#clusterCut
table(clusterCut, tmp$LocalizationSite)
aggregate(tmp[, 2:9],by=list(clusterCut),mean)
plot(PrincipalComponent1, PrincipalComponent2, col=clusterCut)
library(kknn)
cl   <- specClust(clustering.data, centers=8, nn=50, iter.max=100)
#cl
plot(PrincipalComponent1, PrincipalComponent2, col=cl$cluster)
table(cl$cluster, tmp$LocalizationSite)
aggregate(tmp[, 2:9],by=list(cl$cluster),mean)
set.seed(100)
km <- kmeans(clustering.data, 8, iter.max = 30, nstart=30)
#km
km$cluster
plot(PrincipalComponent1, PrincipalComponent2, col=km$cluster)
points(km$centers, pch=16)
aggregate(tmp[, 2:9],by=list(km$cluster),mean)
table(km$cluster, tmp$LocalizationSite)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('yeast.csv')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
knitr::opts_chunk$set(echo = TRUE)
library(FDclassifieR)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('data/agaricus-lepiota.data')
tmp_names <- read.table('data/agaricus-lepiota.names')
tmp <- read.csv('data/agaricus-lepiota.data')
tmp_names <- c('cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor',
'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',
'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',
'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color',
'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat')
names(tmp)<- tmp_names
tmp <- read.csv('data/agaricus-lepiota.data')
tmp_names <- c('class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor',
'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',
'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',
'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color',
'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat')
names(tmp)<- tmp_names
# choose only 'CYT' and 'NUC', ignore SequnceName
Mushroom <- tmp[,2:ncol(tmp)]
Mushroom$Class <- ifelse(tmp[,1] == 'e', 'edible', 'poisonous')
inTraining0 <- createDataPartition(Mushroom$Class, p = .75, list = FALSE)
training <- Mushroom[ inTraining0,]
testing  <- Mushroom[-inTraining0,]
testingY <- as_label(Mushroom[-inTraining0, ncol(Mushroom)])
# choose only 'CYT' and 'NUC', ignore SequnceName
Mushroom <- tmp[,2:ncol(tmp)]
Mushroom$Class <- as.factor(ifelse(tmp[,1] == 'e', 'edible', 'poisonous'))
inTraining0 <- createDataPartition(Mushroom$Class, p = .75, list = FALSE)
training <- Mushroom[ inTraining0,]
testing  <- Mushroom[-inTraining0,]
testingY <- as_label(Mushroom[-inTraining0, ncol(Mushroom)])
table(Mushroom[ inTraining0, ncol(Mushroom)])
pca <- princomp(Mushroom[, -23], cor=T) # principal components analysis using correlation matrix
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
devtools::load_all(".")
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
# choose only 'CYT' and 'NUC', ignore SequnceName
Mushroom <- tmp[,2:ncol(tmp)]
Mushroom <- Mushroom[, -`veil-type`]
# choose only 'CYT' and 'NUC', ignore SequnceName
Mushroom <- tmp[,2:ncol(tmp)]
Mushroom <- Mushroom[, -16]
Mushroom$Class <- as.factor(ifelse(tmp[,1] == 'e', 'edible', 'poisonous'))
inTraining0 <- createDataPartition(Mushroom$Class, p = .75, list = FALSE)
training <- Mushroom[ inTraining0,]
testing  <- Mushroom[-inTraining0,]
testingY <- as_label(Mushroom[-inTraining0, ncol(Mushroom)])
devtools::load_all(".")
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
?read.csv
tmp <- read.csv('data/agaricus-lepiota.data', na.strings = '?')
tmp_names <- c('class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor',
'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',
'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',
'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color',
'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat')
names(tmp)<- tmp_names
# choose only 'CYT' and 'NUC', ignore SequnceName
Mushroom <- tmp[,2:ncol(tmp)]
Mushroom <- Mushroom[, -16]
Mushroom$Class <- as.factor(ifelse(tmp[,1] == 'e', 'edible', 'poisonous'))
inTraining0 <- createDataPartition(Mushroom$Class, p = .75, list = FALSE)
training <- Mushroom[ inTraining0,]
testing  <- Mushroom[-inTraining0,]
testingY <- as_label(Mushroom[-inTraining0, ncol(Mushroom)])
table(Mushroom[ inTraining0, ncol(Mushroom)])
t1 <- mtrainer(c('nnet', 'rda')) %>%
train(Class~., training, update=F) %>%
predict(newdata=testing)
testingY
Mushroom[,1]
