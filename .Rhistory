set.seed(1024)
data(Sonar)
inTraining0 <- createDataPartition(Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTraining0,]
testing  <- Sonar[-inTraining0,]
testingY <- as_label(Sonar[-inTraining0, ncol(Sonar)])
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer(model_list, dataInfo = 'Sonar')
t1 <- predict(t1, newdata=testing)
plot_ensemble(fde1, method='correlation', alpha=0.8)
fde1 <- fde(t1$predictions, testingY)
plot_ensemble(fde1, method='correlation', alpha=0.8)
devtools::load_all(".")
plot_ensemble(fde1, method='correlation', alpha=0.8)
knitr::opts_chunk$set(echo = TRUE)
library(mlbench)
library(FDclassifieR)
set.seed(1024)
data(Ionosphere)
Iono <- Ionosphere
Iono <- Iono[,-2]
Iono$V1 <- as.numeric(as.character(Iono$V1))
inTraining0 <- createDataPartition(Iono$Class, p = .75, list = FALSE)
training <- Iono[ inTraining0,]
testing  <- Iono[-inTraining0,]
testingY <- as_label(Iono[-inTraining0, ncol(Iono)])
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer(model_list, dataInfo = 'Iono')
t1 <- predict(t1, newdata=testing)
#auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions, testingY)
#fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_ensemble(fde1, method='correlation', amax=1)
knitr::opts_chunk$set(echo = TRUE)
library(FDclassifieR)
set.seed(1024)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('data/yeast.csv')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer(model_list, dataInfo = 'Yeast')
t1 <- predict(t1, newdata=testing)
#auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions, testingY)
#fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_ensemble(fde1, method='correlation', alpha=0.8, amax=0.75)
#set.seed(1024)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('data/yeast.csv')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
t1 <- predict(t1, newdata=testing)
#auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions, testingY)
#fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_ensemble(fde1, method='correlation', alpha=0.8, amax=0.75)
plot_cor(fde1, class_flag='positive')
plot_ensemble(fde1, method='correlation', alpha=0.8, amax=0.75)
plot_ensemble(fde1, method='correlation', alpha=0.8)
plot_ensemble(fde1, method='invauc', alpha=0.8)
plot_ensemble(fde1, method='auc', alpha=0.8)
plot_ensemble(fde1, method='correlation', alpha=0.8)
#set.seed(1024)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('data/yeast.csv')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
t1 <- predict(t1, newdata=testing)
#auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions, testingY)
#fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_ensemble(fde1, method='correlation', alpha=0.8)
#set.seed(1024)
#yeast <- read_table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"))
tmp <- read.table('data/yeast.csv')
names(tmp)<- c("SequenceName", "mcg", "gvh", "alm",
"mit", "erl", "pox", "vac", "nuc", "LocalizationSite")
#head(tmp)
#table(tmp$LocalizationSite)
# choose only 'CYT' and 'NUC', ignore SequnceName
Yeast <- tmp[tmp$LocalizationSite %in% c('CYT', 'NUC'), 2:10]
names(Yeast)[ncol(Yeast)] <- 'Site'
Yeast$Site <- factor(Yeast$Site, c('CYT', 'NUC'))
inTraining0 <- createDataPartition(Yeast$Site, p = .75, list = FALSE)
training <- Yeast[ inTraining0,]
testing  <- Yeast[-inTraining0,]
testingY <- as_label(Yeast[-inTraining0, ncol(Yeast)])
t1 <- predict(t1, newdata=testing)
#auclist <- apply(t1$predictions, 2, auc.rank, testingY)
fde1 <- fde(t1$predictions, testingY)
#fde1 <- predict_performance(fde1, auclist, attr(testingY, 'rho'))
plot_ensemble(fde1, method='correlation', alpha=0.8)
plot_ensemble(fde1, method='invauc', alpha=0.8)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
train <- fread(paste0(dirname, '/', 'train.csv'))
y <- as.factor(train$target)
rho <- sum(y == 1)/length(y)
predictions <- matrix(nrow = 892816, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
dim(predictions)
head(predictions)
hist(predictions[, 7])
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(FDclassifieR)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(FDclassifieR)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
train <- fread(paste0(dirname, '/', 'train.csv'))
y <- as.factor(train$target)
rho <- sum(y == 1)/length(y)
predictions <- matrix(nrow = 892816, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
dim(predictions)
fde1 <- fdensemble(predictions)
fde1 <- predict_performance(fde1, auclist, rho, alpha=1)
devtools::load_all(".")
fde1 <- predict_performance(fde1, auclist, rho, alpha=1)
devtools::load_all(".")
fde1 <- fdensemble(predictions)
devtools::load_all(".")
fde1 <- fdensemble(predictions)
fde1 <- predict_performance(fde1, auclist, rho, alpha=1)
devtools::load_all(".")
fde1 <- predict_performance(fde1, auclist, rho, alpha=1)
plot_cor(fde1, class_flag='positive')
submit <- data.table(id=tmp$id, target=fde1@estimated_prob)
fwrite(submit, file='submission.csv')
sapply(auclist, paste0, 'A')
?sapply
?mapply
mapply(paste0, rep('A',9), auclist)
mapply(paste0, rep('A',9), auclist, SIMPLIFY = T)
mapply(paste0, rep('A',9), auclist, USE.NAMES = F)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
# calculate prevalence from train data set
train <- fread(paste0(dirname, '/', 'train.csv'))
y <- as.factor(train$target)
rho <- sum(y == 1)/length(y)
# create prediction matrix
predictions <- matrix(nrow = 892816, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
colnames(predictions) <- mapply(paste0, rep('A',length(flist)), auclist)
dim(predictions)
head(predictions)
fde1 <- fdensemble(predictions)
fde1 <- predict_performance(fde1, auclist, rho, alpha=1)
plot_cor(fde1, class_flag='positive')
set.seed(1024)
tmp <- train[, 3:59]
y <- train$target
inTraining0 <- createDataPartition(y, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(testingY)
set.seed(1024)
tmp <- train[, 3:59]
y <- as.factor(train$target)
inTraining0 <- createDataPartition(y, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer('rf', dataInfo = 'Porto')
head(tmp)
colnames(train)
set.seed(1024)
tmp <- train[, c(3:59,2)]
y <- as.factor(train$target)
inTraining0 <- createDataPartition(y, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
t1 <- train(t1, target~., training, update=T)
set.seed(1024)
tmp <- train[, c(3:59,2)]
tmp$target <- as.factor(tmp$target)
y <- as.factor(train$target)
inTraining0 <- createDataPartition(y, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
t1 <- train(t1, target~., training, update=T)
tmp$target
str(tmp)
set.seed(1024)
tmp <- train[, c(3:59,2)]
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer('rf', dataInfo = 'Porto')
t1 <- train(t1, target~., training, update=T)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
# calculate prevalence from train data set
train <- fread(paste0(dirname, '/', 'train.csv'), na.strings=c("-1","-1.0"))
train <- train %>%
mutate_at(vars(ends_with("cat")), funs(factor)) %>%
mutate_at(vars(ends_with("bin")), funs(as.logical)) %>%
mutate(target = as.factor(target))
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(FDclassifieR)
library(dplyr)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
# calculate prevalence from train data set
train <- fread(paste0(dirname, '/', 'train.csv'), na.strings=c("-1","-1.0"))
train <- train %>%
mutate_at(vars(ends_with("cat")), funs(factor)) %>%
mutate_at(vars(ends_with("bin")), funs(as.logical)) %>%
mutate(target = as.factor(target))
rho <- sum(y == 1)/length(y)
# create prediction matrix
predictions <- matrix(nrow = 892816, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
colnames(predictions) <- mapply(paste0, rep('A',length(flist)), auclist)
dim(predictions)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
# calculate prevalence from train data set
train <- fread(paste0(dirname, '/', 'train.csv'), na.strings=c("-1","-1.0"))
train <- train %>%
mutate_at(vars(ends_with("cat")), as.factor) %>%
mutate_at(vars(ends_with("bin")), as.logical) %>%
mutate(target = as.factor(target))
rho <- sum(y == 1)/length(y)
# create prediction matrix
predictions <- matrix(nrow = 892816, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
colnames(predictions) <- mapply(paste0, rep('A',length(flist)), auclist)
dim(predictions)
?sample
?sample
set.seed(1024)
tmp <- train[, c(3:59,2)] %>% sample_n(2000)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
set.seed(1024)
tmp <- train[, c(3:59,2)] %>% sample_n(4000)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer('rf', dataInfo = 'Porto')
t1 <- train(t1, target~., training, update=T)
dirname <- 'data_porto_maxGini_0.29'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- (as.numeric(gsub(".csv", "", flist)) + 1)/2
# calculate prevalence from train data set
train <- fread(paste0(dirname, '/', 'train.csv'), na.strings=c("-1","-1.0"))
#train <- train %>%
#  mutate_at(vars(ends_with("cat")), as.factor) %>%
#  mutate_at(vars(ends_with("bin")), as.logical) %>%
#  mutate(target = as.factor(target))
rho <- sum(y == 1)/length(y)
# create prediction matrix
predictions <- matrix(nrow = 892816, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
colnames(predictions) <- mapply(paste0, rep('A',length(flist)), auclist)
dim(predictions)
set.seed(1024)
tmp <- train[, c(3:59,2)] %>% sample_n(4000)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
t1 <- train(t1, target~., training, update=T)
set.seed(1024)
tmp <- train[, c(3:59,2)] %>% sample_n(4000)
cat_vars <- names(tmp)[grepl('_cat$', names(tmp))]
tmp <- tmp %>%
mutate_at(.vars = cat_vars, .funs = as.factor)
tmp <- model.matrix(~ . - 1, data = tmp)
?model.matrix
tmp
tmp <- as.data.frame(tmp)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
str(tmp)
table(training$target)
set.seed(1024)
tmp <- train[, c(3:59,2)] %>% sample_n(8000)
cat_vars <- names(tmp)[grepl('_cat$', names(tmp))]
tmp <- tmp %>%
mutate_at(.vars = cat_vars, .funs = as.factor)
tmp <- model.matrix(~ . - 1, data = tmp)
tmp <- as.data.frame(tmp)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer('rf', dataInfo = 'Porto')
t1 <- train(t1, target~., training, update=T)
plot(t1)
t1 <- t1 %>%
addmodel.mtrainer(c('nnet', 'rda', 'pls')) %>%
train(target~., training)
t1 <- t1 %>%
addmodel.mtrainer(c('rda', 'pls')) %>%
train(target~., training)
plot(t1)
set.seed(1024)
tmp <- train[complete.cases(tmp), c(3:59,2)]
set.seed(1024)
tmp <- train[complete.cases(tmp), ]
skim(train)
library(skimr)
skim(train)
set.seed(1024)
# remove complete_rate < 0.9 columns
tmp <- train[, -c(23,26,28)]
tmp <- train[complete.cases(tmp), ]
# change categorical variables to one-hot vectors
cat_vars <- names(tmp)[grepl('_cat$', names(tmp))]
tmp <- tmp %>%
mutate_at(.vars = cat_vars, .funs = as.factor)
tmp <- model.matrix(~ . - 1, data = tmp)
tmp <- as.data.frame(tmp)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
set.seed(1024)
# remove complete_rate < 0.9 columns
tmp <- train[, -c(23,26,28)]
tmp <- train[complete.cases(tmp), ]
# change categorical variables to one-hot vectors
cat_vars <- names(tmp)[grepl('_cat$', names(tmp))]
tmp <- tmp %>%
sample_n(8000) %>%
mutate_at(.vars = cat_vars, .funs = as.factor)
tmp <- model.matrix(~ . - 1, data = tmp)
tmp <- as.data.frame(tmp)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
set.seed(1024)
# remove complete_rate < 0.9 columns
tmp <- train[, -c(23,26,28)]
tmp <- train[complete.cases(tmp), ]
# change categorical variables to one-hot vectors
cat_vars <- names(tmp)[grepl('_cat$', names(tmp))]
tmp <- tmp %>%
sample_n(10000) %>%
mutate_at(.vars = cat_vars, .funs = as.factor)
tmp <- model.matrix(~ . - 1, data = tmp)
tmp <- as.data.frame(tmp)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
set.seed(1024)
# remove complete_rate < 0.9 columns
tmp <- train[, -c(23,26,28)]
tmp <- train[complete.cases(tmp), ]
# change categorical variables to one-hot vectors
cat_vars <- names(tmp)[grepl('_cat$', names(tmp))]
tmp <- tmp %>%
sample_n(30000) %>%
mutate_at(.vars = cat_vars, .funs = as.factor)
tmp <- model.matrix(~ . - 1, data = tmp)
tmp <- as.data.frame(tmp)
tmp$target <- as.factor(ifelse(tmp$target == 1, 'filed', 'not'))
inTraining0 <- createDataPartition(tmp$target, p = .75, list = FALSE)
training <- tmp[ inTraining0,]
testing  <- tmp[-inTraining0,]
testingY <- as_label(y[-inTraining0])
table(training$target)
model_list <- c('nnet', 'rda', 'svmLinear', 'svmRadial', 'pls', 'knn', 'earth', 'avNNet', 'mlp', 'nb', 'rf', 'rpart', 'ctree', 'C5.0', 'gbm', 'bayesglm', 'glm', 'glmnet', 'simpls')
t1 <- mtrainer(c('rda', 'pls', 'glm'), dataInfo = 'Porto')
t1 <- train(t1, target~., training, update=T)
t1$model_list
t1$model_list <- c('glm', 'rda', 'pls')
t1 <- train(t1, target~., training, update=T)
saveRDS(train, 'data-Porto.RData')
saveRDS(tmp, 'data-Porto-train.RData')
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
dirname <- 'data_cat_maxAUC_0.78'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- as.numeric(gsub(".csv", "", flist))
train <- fread(paste0(dirname, '/', 'train.csv'))
y <- as.factor(train$target)
rho <- sum(y == 1)/length(y)
predictions <- matrix(nrow = 400000, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
dim(predictions)
saveRDS(train, file='kaggle/data-CATII.RData')
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
dirname <- 'data_west_nile_maxAUC_0.85'
flist <- list.files(path=dirname, pattern='0.*.csv')
auclist <- as.numeric(gsub(".csv", "", flist))
train <- fread(paste0(dirname, '/', 'train.csv'))
y <- as.factor(train$WnvPresent)
rho <- sum(y == 1)/length(y)
predictions <- matrix(nrow = 116293, ncol=length(flist))
i <- 1
for (f in flist) {
tmp <- fread(paste0(dirname, '/', f))
predictions[ ,i] <- tmp[[2]]
i <- i + 1
}
dim(predictions)
saveRDS(train, file='kaggle/data-WestNile.RData')
